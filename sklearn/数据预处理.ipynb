{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距离（判断样本的相似度）\n",
    "- 闵科夫斯基距离\n",
    "- 曼哈顿距离\n",
    "- 欧拉距离\n",
    "- 极大距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.spatial.distance import pdist\n",
    "X=np.vstack([x,y])\n",
    "pdist(X, metric='euclidean', *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pdist(X, 'euclidean')\n",
    "\n",
    "Y = pdist(X, 'minkowski', p=2.)\n",
    "\n",
    "Y = pdist(X, 'cityblock')\n",
    "\n",
    "Y = pdist(X, 'seuclidean', V=None)\n",
    "\n",
    "Y = pdist(X, 'sqeuclidean')\n",
    "\n",
    "Y = pdist(X, 'cosine')\n",
    "\n",
    "Y = pdist(X, 'correlation')\n",
    "\n",
    "Y = pdist(X, 'hamming')\n",
    "\n",
    "Y = pdist(X, 'jaccard')\n",
    "\n",
    "Y = pdist(X, 'chebyshev')\n",
    "\n",
    "Y = pdist(X, 'canberra')\n",
    "\n",
    "Y = pdist(X, 'braycurtis')\n",
    "\n",
    "Y = pdist(X, 'mahalanobis', VI=None)\n",
    "\n",
    "Y = pdist(X, 'yule')\n",
    "\n",
    "Y = pdist(X, 'matching')\n",
    "\n",
    "Y = pdist(X, 'dice')\n",
    "\n",
    "Y = pdist(X, 'kulsinski')\n",
    "\n",
    "Y = pdist(X, 'rogerstanimoto')\n",
    "\n",
    "Y = pdist(X, 'russellrao')\n",
    "\n",
    "Y = pdist(X, 'sokalmichener')\n",
    "\n",
    "Y = pdist(X, 'sokalsneath')\n",
    "\n",
    "Y = pdist(X, 'wminkowski', p=2, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 余弦相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欧式距离：绝对距离  \n",
    "余弦相似度：方向差异"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缺失值处理\n",
    "- 删除法：删除样本或删除特征  \n",
    "- 均值填补：连续数据用平均值填补，离散数据用众数填补\n",
    "- 随机填补\n",
    "- 基于模型的填补：将缺失特征y当作预测目标\n",
    "- 哑变量：对于离散型的\n",
    "- EM算法填补"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.sklearn方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleImputer(missing_values=nan,       # 缺失值的占位符\n",
    "              trategy='mean',           # 列平均值mean,中位数median，众数most_frequent，常量constant\n",
    "              fill_value=None,          # 值\n",
    "              verbose=0,                # 控制详细度\n",
    "              copy=True,                # 是否重新复制一份\n",
    "              add_indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.   2.   3. ]\n",
      " [ 4.   3.5  6. ]\n",
      " [10.   5.   9. ]]\n",
      "[[ 7.   2.   3. ]\n",
      " [ 4.   3.5  6. ]\n",
      " [10.   3.5  9. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')   # 类\n",
    "\n",
    "imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])               # 实例化\n",
    "\n",
    "print(imp_mean.fit_transform([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]]))\n",
    "\n",
    "X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
    "\n",
    "print(imp_mean.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(X[, y])              # 找到imputer\n",
    "\n",
    "fit_transform(X[, y])    # 自己填充\n",
    "\n",
    "transform(X)             # 用找到的imputer，填充其他的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.pandas方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# pd.isna( 对象 )    # 返回bool类型对象，该对象和源对象一样\n",
    "# pd.notna( 对象 )\n",
    "\n",
    "# 对象.isna()\n",
    "# 对象.notna()\n",
    "\n",
    "\n",
    "# 对象.fillna(0)\n",
    "# 对象.fillna(method='pad')    向前pad / ffill    向后bfill / backfill\n",
    "\n",
    "# 对象.dropna()                删除轴标签缺少数据   指定参数axis=0\n",
    "\n",
    "# 对象.replace(取代值, 缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离群值检测\n",
    "- 统计方法：在上下a分位点之外的值是异常值\n",
    "- 近邻的方法：点周围的密度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocalOutlierFactor(n_neighbors=20,      #领域数\n",
    "                   algorithm='auto',    #{'auto'，'ball_tree'，'kd_tree'，'brute'}，可选\n",
    "                   leaf_size=30,        # Leaf size 用于上面的BallTree or KDTree\n",
    "                   metric='minkowski',   #用于距离计算的度量\n",
    "                   p=2,                  #闵可夫距离下，p=1，Manhattan；p=2，euclidean_distance\n",
    "                   metric_params=None,  #度量功能的其他关键字参数。\n",
    "                   contamination='auto', #异常值比例\n",
    "                   novelty=False,        #LocalOutlierFactor仅用于异常值检测（novelty = False）\n",
    "                   n_jobs=None)          #并行个数\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "metric的取值（第一个标题）\n",
    "来自scikit-learn：['cityblock'，'cosine'，'euclidean'，'l1'，'l2'，'manhattan']\n",
    "\n",
    "来自scipy.spatial.distance：['braycurtis'，'canberra'，'chebyshev'，'correlation'，'dice，'hamming'，\n",
    "'jaccard'，'kulsinski'，'mahalanobis'，'minkowski'，'rogerstanimoto '，\n",
    "'russellrao'，'seuclidean'，'sokalmichener'，'sokalsneath'，'sqeuclidean'，'yule']\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1  1]\n",
      "[ -0.98214286  -1.03703704 -73.36970899  -0.98214286]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "X = [[-1.1], [0.2], [101.1], [0.3]]\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=2)    # 类\n",
    "\n",
    "print(clf.fit_predict(X))\n",
    "\n",
    "print(clf.negative_outlier_factor_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_outlier_factor_    # 属性。训练样本的LOF。越高，越正常。(=-1)inliner\n",
    "\n",
    "n_neighbors_                # 领域数\n",
    "\n",
    "fit(X[, y])                 # 使用X作为训练数据拟合模型\n",
    "\n",
    "fit_predict(X[, y])         # 将模型拟合到训练集X并返回标签\n",
    "\n",
    "kneighbors([X, n_neighbors, …])  # 找到一个点的K领域\n",
    "\n",
    "kneighbors_graph([X, n_neighbors, mode])  # 计算加权图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据转换的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征编码\n",
    "- 数字编码（缺点：次序问题）\n",
    "- One-Hot编码（缺点：维数增多，引入了特征相关性）\n",
    "- 哑变量编码（将K个变成K-1个二元特征）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数字编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder()\n",
      "[1 1 0 0 2]\n",
      "['F' 'M' 'unknow']\n",
      "[1 2 0 1]\n",
      "['M' 'M' 'M' 'M' 'unknow' 'F']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder        # 类\n",
    "\n",
    "le = LabelEncoder()                                    # 实例化\n",
    "\n",
    "print(le.fit([\"M\", \"M\", \"F\", \"F\",\"unknow\"]))           # 拟合数字编码\n",
    "\n",
    "print(le.fit_transform([\"M\", \"M\", \"F\", \"F\",\"unknow\"])) # 拟合数字编码并返回编码\n",
    "\n",
    "print(le.classes_)                                     # 输出拟合的标签\n",
    "\n",
    "print(le.transform([\"M\",\"unknow\",\"F\",\"M\"]))            # 用实例化后的le转化其他的编码\n",
    "\n",
    "print(le.inverse_transform([1,1,1,1,2,0]))             # 将标签翻译成数字编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0：F  \n",
    "1：M  \n",
    "2: unknow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_             #属性，输出拟合的所有标签\n",
    "\n",
    "fit(y)               # 拟合标签编码器\n",
    "\n",
    "fit_transform(y)     # 拟合标签编码器并返回编码的标签\n",
    "\n",
    "inverse_transform(y) # 将标签转换回原始编码。\n",
    "\n",
    "transform(y)         # 将标签转换为规范化编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.sklearn方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "输入：整数或字符串之类的数组\n",
    "输出：稀疏矩阵或密集数组\n",
    "\"\"\"\n",
    "OneHotEncoder(categories='auto',               # 输入自动\n",
    "              drop=None,                      # 删除某些列None，'first'，drop[i]\n",
    "              sparse=True,                    # True，返回稀疏矩阵，否则返回数组\n",
    "              dtype=<class 'numpy.float64'>,  # 输出类型\n",
    "              handle_unknown='error')          # 引发错误或忽略(ignore)，默认引发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
      "              handle_unknown='ignore', sparse=True)\n",
      "[[0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 0.]]\n",
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[['Male' 1]\n",
      " [None 2]]\n",
      "['gender_Female' 'gender_Male' 'group_1' 'group_2' 'group_3']\n",
      "OneHotEncoder(categories='auto', drop='first', dtype=<class 'numpy.float64'>,\n",
      "              handle_unknown='error', sparse=True)\n",
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder   # 类\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')       # 实例化\n",
    "\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]    \n",
    "\n",
    "print(enc.fit(X))                                  # 拟合One-Hot编码\n",
    "\n",
    "print(enc.fit_transform(X).toarray())              # 拟合One-Hot编码并返回One-Hot编码\n",
    "\n",
    "print(enc.categories_)                             # 在拟合过程中确定的每个特征的类别\n",
    "\n",
    "print(enc.transform([['Female', 1], ['Male', 4]]).toarray())\n",
    "\n",
    "print(enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]]))\n",
    "\n",
    "print(enc.get_feature_names(['gender', 'group']))\n",
    "\n",
    "drop_enc = OneHotEncoder(drop='first').fit(X)      # 删除每个功能中的第一个类别\n",
    "\n",
    "print(drop_enc)\n",
    "\n",
    "print(drop_enc.categories_)\n",
    "\n",
    "print(drop_enc.fit_transform(X).toarray())\n",
    "\n",
    "print(drop_enc.transform([['Female', 1], ['Male', 2]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        F  M  1  2  3\n",
    "(M,1)   0  1  1  0  0\n",
    "(F,3)   1  0  0  0  1\n",
    "(F,2)   1  0  0  1  0\n",
    "\n",
    "------------------------\n",
    "        M  2  3\n",
    "(M,1)   1  0  0\n",
    "(F,3)   0  0  1\n",
    "(F,2)   0  1  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_            # 属性，在拟合过程中确定的每个特征的类别\n",
    "\n",
    "fit(X[, y])            # 使OneHotEncoder适应X\n",
    "\n",
    "fit_transform(X[, y])  # 使OneHotEncoder适应X，然后变换X\n",
    "\n",
    "get_feature_names(input_features=None) # 返回输出要素的名称\n",
    "\n",
    "inverse_transform(X)   # 将数据转换回原始表示形式\n",
    "\n",
    "transform(X)            # 使用OneHotEncoder转换X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.pandas方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.get_dummies(data, \n",
    "                   prefix=None,              # 用于追加DataFrame列名称的字符串。\n",
    "                   prefix_sep='_',           # 如果附加前缀，则使用分隔符_\n",
    "                   dummy_na=False,          # 增加一列显示这行是否空值，如果没有空值那么为0，如果这行为空值，那么为1\n",
    "                   columns=None,            # 要编码的DataFrame中的列名，如果columns为None，则将转换所有对象或类别为 dtype 的列\n",
    "                   sparse=False,            #  True稀疏，False numpy数组\n",
    "                   drop_first=False,        #是否减少一列\n",
    "                   dtype=None)              #类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  1  0  0\n",
      "1  0  1  0\n",
      "2  0  0  1\n",
      "3  1  0  0\n",
      "   a  b  c  NaN\n",
      "0  1  0  0    0\n",
      "1  0  1  0    0\n",
      "2  0  0  1    0\n",
      "3  1  0  0    0\n",
      "   前缀_a  前缀_b  前缀_c\n",
      "0     1     0     0\n",
      "1     0     1     0\n",
      "2     0     0     1\n",
      "3     1     0     0\n",
      "   b  c\n",
      "0  0  0\n",
      "1  1  0\n",
      "2  0  1\n",
      "3  0  0\n",
      "     a    b    c\n",
      "0  1.0  0.0  0.0\n",
      "1  0.0  1.0  0.0\n",
      "2  0.0  0.0  1.0\n",
      "3  1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.Series(['a','b','c','a'])\n",
    "\n",
    "print(pd.get_dummies(data))\n",
    "\n",
    "print(pd.get_dummies(data, dummy_na=True))\n",
    "\n",
    "print(pd.get_dummies(data, prefix='前缀'))\n",
    "\n",
    "print(pd.get_dummies(data, drop_first=True))\n",
    "\n",
    "print(pd.get_dummies(data, dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据标准化\n",
    "- Z-score标准化\n",
    "- Min-Maxi标准化\n",
    "- 小数定标标准化\n",
    "- Logistic标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.preprocessing.StandardScaler\n",
    "sklearn.preprocessing.MinMaxScaler\n",
    "sklearn.preprocessing.RobustScaler #使用对异常值具有鲁棒性的统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Z-score标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler(copy=True,     #是否复制\n",
    "               with_mean=True, #数据是否居中\n",
    "               with_std=True) # 将数据缩放到单位方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[0.5 0.5]\n",
      "[0.25 0.25]\n",
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[[3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(scaler.fit(data))\n",
    "\n",
    "print(scaler.mean_)\n",
    "\n",
    "print(scaler.var_)\n",
    "\n",
    "print(scaler.transform(data))\n",
    "\n",
    "print(scaler.transform([[2, 2]]))   # (2-0.5)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_                        # 属性。训练集中每个特征的平均值\n",
    "\n",
    "var_                         # 属性。训练集中每个要素的方差\n",
    "\n",
    "fit(X[, y])                  # 计算均值和std以用于以后的缩放\n",
    "\n",
    "fit_transform(X[, y])\n",
    "\n",
    "inverse_transform(X[, copy]) # 将数据按比例缩小到原始表示形式\n",
    "\n",
    "partial_fit(X[, y])          # 计算X上的均值和标准差，以便以后标准化\n",
    "\n",
    "transform(X[, y, copy])      # 通过居中和缩放执行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Min-Maxi标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxScaler(feature_range=(0, 1),   #(最小，最大)\n",
    "             copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "[ 1. 18.]\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n",
      "[[1.5 0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "print(scaler.fit(data))\n",
    "\n",
    "print(scaler.data_max_)\n",
    "\n",
    "print(scaler.transform(data))\n",
    "\n",
    "print(scaler.transform([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_            # 属性。查看最小值\n",
    "data_max_            # 属性。查看最大值\n",
    "data_range_          # 属性。最大值-最小值\n",
    "\n",
    "方法同上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Maxi标准化变种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RobustScaler(with_centering=True,           #是否数据居中\n",
    "             with_scaling=True,             #是否缩放到分位数范围\n",
    "             quantile_range=(25.0, 75.0),   #分位数范围\n",
    "             copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征离散化\n",
    "\n",
    "连续变成区间(离散)\n",
    "\n",
    "- 二值离散化\n",
    "- 等距离散化\n",
    "- 等频离散化\n",
    "- 聚类离散化\n",
    "-----------\n",
    "- 信息增益离散化\n",
    "- 卡方离散化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二值离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binarizer(threshold=0.0,     # 低于或等于替换为0，高于替换为1\n",
    "          copy=True)         # 是否复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer(copy=True, threshold=0.0)\n",
      "[[1. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "transformer = Binarizer().fit(X)\n",
    "\n",
    "print(transformer)\n",
    "\n",
    "print(transformer.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(X[, y])\n",
    "\n",
    "fit_transform(X[, y])\n",
    "\n",
    "transform(X[, copy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 等距离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.cut(x,                                 # 必须是一维的数组\n",
    "           bins,                              # 离散化标准：int，标量序列或pd.IntervalIndex\n",
    "           right: bool = True,               # 是否右闭区间\n",
    "           labels=None,                      # 指定标签，长度和bin一样\n",
    "           retbins: bool = False,            # 是否返回bins\n",
    "           precision: int = 3,               # 存储和显示bins标签的精度\n",
    "           include_lowest: bool = False,     # 第一个时间间隔是否应包含在内\n",
    "           duplicates: str = 'raise')        # 如果bin边缘不是唯一的，则 raise ValueError或drop non-uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], (0.994, 3.0]]\n",
      "Categories (3, interval[float64]): [(0.994, 3.0] < (3.0, 5.0] < (5.0, 7.0]] \n",
      "\n",
      "([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], (0.994, 3.0]]\n",
      "Categories (3, interval[float64]): [(0.994, 3.0] < (3.0, 5.0] < (5.0, 7.0]], array([0.994, 3.   , 5.   , 7.   ])) \n",
      "\n",
      "[bad, good, medium, medium, good, bad]\n",
      "Categories (3, object): [bad < medium < good]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3),'\\n')\n",
    "\n",
    "print(pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True),'\\n')\n",
    "\n",
    "print(pd.cut(np.array([1, 7, 5, 4, 6, 3]),3, labels=[\"bad\", \"medium\", \"good\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 等频离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.qcut(x,                            # 必须是一维的数组或Series对象\n",
    "            q,                            # 分位数  4为四分位数\n",
    "            labels=None, \n",
    "            retbins: bool = False, \n",
    "            precision: int = 3, \n",
    "            duplicates: str = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[good, good, medium, bad, bad]\n",
       "Categories (3, object): [good < medium < bad]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.qcut(range(5), 3, labels=[\"good\", \"medium\", \"bad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
